{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## All necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd tools/ && python setup_opera_distance_metric.py build_ext --inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn import Sequential\n",
    "from torch.distributions import Bernoulli\n",
    "\n",
    "\n",
    "from tools.opera_distance_metric import generate_k_nearest_graph, \\\n",
    "                                        opera_distance_metric_py, \\\n",
    "                                        generate_radius_graph\n",
    "\n",
    "from graph_rnn import bfs_seq, encode_adj, decode_adj\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pack_sequence, pad_sequence, pad_packed_sequence\n",
    "import random\n",
    "\n",
    "sns.set(font_scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./data/showers.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs_handmade(G, start):\n",
    "    visited, queue = set(), [start]\n",
    "    while queue:\n",
    "        vertex = queue.pop(0)\n",
    "        if vertex not in visited:\n",
    "            visited.add(vertex)\n",
    "            edges = sorted(G.out_edges(vertex, data=True), key=lambda x: x[2]['weight'])\n",
    "            queue.extend(set([x[1] for x in edges]) - visited)\n",
    "    return np.array(list(visited))[np.argsort(np.array(list(G.nodes())))]\n",
    "\n",
    "\n",
    "def encode_adj(adj, max_prev_node=10, is_full = False):\n",
    "    '''\n",
    "    :param adj: n*n, rows means time step, while columns are input dimension\n",
    "    :param max_degree: we want to keep row number, but truncate column numbers\n",
    "    :return:\n",
    "    '''\n",
    "    if is_full:\n",
    "        max_prev_node = adj.shape[0] - 1\n",
    "    \n",
    "    # successors only\n",
    "    adj = adj\n",
    "    \n",
    "    # pick up lower tri\n",
    "    adj = np.tril(adj, k=-1)\n",
    "    n = adj.shape[0]\n",
    "    adj = adj[1:n, 0:n-1]\n",
    "\n",
    "    # use max_prev_node to truncate\n",
    "    # note: now adj is a (n-1) * (n-1) matrix\n",
    "    adj_output = np.zeros((adj.shape[0], max_prev_node))\n",
    "    for i in range(adj.shape[0]):\n",
    "        input_start = max(0, i - max_prev_node + 1)\n",
    "        input_end = i + 1\n",
    "        output_start = max_prev_node + input_start - input_end\n",
    "        output_end = max_prev_node\n",
    "        adj_output[i, output_start:output_end] = adj[i, input_start:input_end]\n",
    "        adj_output[i,:] = adj_output[i,:][::-1] # reverse order\n",
    "\n",
    "    return adj_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prev_node = 10\n",
    "graph_state_size = 64\n",
    "embedding_size = 256\n",
    "edge_rnn_embedding_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphrnn_shower = namedtuple('graphrnn_shower', field_names=['x', \n",
    "                                                             'adj', \n",
    "                                                             'adj_out', \n",
    "                                                             'adj_squared', \n",
    "                                                             'ele_p',\n",
    "                                                             'distances'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_shower_for_graphrnn(shower, device, k=4, symmetric=False):\n",
    "    X = np.vstack([\n",
    "        np.arange(len(shower.SX)),\n",
    "        shower.SX,\n",
    "        shower.SY,  \n",
    "        shower.SZ, \n",
    "        shower.TX,\n",
    "        shower.TY,\n",
    "        shower.ele_P]\n",
    "    ).T\n",
    "    print(len(X))\n",
    "    edges_from, edges_to, distances = generate_k_nearest_graph(X, k=k, symmetric=symmetric)\n",
    "    G = nx.Graph()\n",
    "    edges = []\n",
    "    for i in range(len(distances)):\n",
    "        edges.append((edges_from[i], edges_to[i], {'weight': distances[i]}))\n",
    "        \n",
    "    G.add_edges_from(edges)\n",
    "    G = nx.DiGraph(G)\n",
    "\n",
    "    adj = np.asarray(nx.to_numpy_matrix(G))\n",
    "\n",
    "    start_idx = 0\n",
    "    x_idx = np.array(bfs_handmade(G, start_idx))\n",
    "    adj = adj[np.ix_(x_idx, x_idx)]\n",
    "\n",
    "    # actual data\n",
    "    adj_output = encode_adj(adj, max_prev_node=max_prev_node)\n",
    "    X = X[x_idx, 1:]\n",
    "    X = X / np.array([1e3, 1e3, 1e3, 1, 1, 1])\n",
    "    distances = np.log(1. + np.array(distances))\n",
    "    \n",
    "    # for now forget about distances\n",
    "    # TODO: what to do with distances?\n",
    "    adj_output[adj_output!=0] = 1.\n",
    "    \n",
    "    adj_output_t = torch.tensor(np.append(np.ones((1, max_prev_node)), \n",
    "                                          adj_output, axis=0), \n",
    "                                dtype=torch.float32).to(device).view(1, -1, max_prev_node)\n",
    "    \n",
    "    X_t = torch.tensor(X[:, :-1], dtype=torch.float32).to(device).view(1, -1, 5)\n",
    "\n",
    "    adj_out_t = torch.LongTensor(np.array(list(nx.from_numpy_matrix(decode_adj(adj_output), \n",
    "                                                                    create_using=nx.DiGraph).edges())).T).to(device)\n",
    "    \n",
    "    adj_squared_t = torch.tensor(adj, dtype=torch.float32).to(device)\n",
    "    \n",
    "    return graphrnn_shower(adj=adj_output_t, \n",
    "                           x=X_t, \n",
    "                           adj_out=adj_out_t,\n",
    "                           adj_squared=adj_squared_t,\n",
    "                           distances=distances,\n",
    "                           ele_p=torch.tensor(X[-1, -1], dtype=torch.float32).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "showers_train = []\n",
    "for i, shower in list(df.iterrows())[:3]:\n",
    "    showers_train.append(preprocess_shower_for_graphrnn(shower, device=device, k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GraphRNN \n",
    "\n",
    "Generates embeddings for nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphRNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, \n",
    "                 num_layers, has_input=True, has_output=False, output_size=None):\n",
    "        super(GraphRNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.has_input = has_input\n",
    "        self.has_output = has_output\n",
    "\n",
    "        if has_input:\n",
    "            self.input = nn.Linear(input_size, embedding_size)\n",
    "            self.rnn = nn.GRU(input_size=embedding_size, hidden_size=hidden_size, \n",
    "                              num_layers=num_layers, batch_first=True)\n",
    "        else:\n",
    "            self.rnn = nn.GRU(input_size=input_size, hidden_size=hidden_size, \n",
    "                              num_layers=num_layers, batch_first=True)\n",
    "        if has_output:\n",
    "            self.output = nn.Sequential(\n",
    "                nn.Linear(hidden_size, embedding_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(embedding_size, output_size)\n",
    "            )\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        # initialize\n",
    "        self.hidden_emb = nn.Sequential(\n",
    "            nn.Linear(1, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, self.hidden_size)\n",
    "        )\n",
    "        self.hidden = None  # need initialize before forward run\n",
    "\n",
    "    def init_hidden(self, input, batch_size):\n",
    "        hidden_emb = torch.cat([self.hidden_emb(input).view(1, batch_size, self.hidden_size), \n",
    "                                torch.zeros(self.num_layers - 1, batch_size, self.hidden_size).cuda()])\n",
    "        return hidden_emb\n",
    "\n",
    "    def forward(self, input_raw, pack=False, input_len=None):\n",
    "        output_raw_emb, output_raw, output_len = None, None, None\n",
    "        \n",
    "        if self.has_input:\n",
    "            input = self.input(input_raw)\n",
    "            input = self.relu(input)\n",
    "        else:\n",
    "            input = input_raw\n",
    "        if pack:\n",
    "            \n",
    "            pass # input = pack_sequence(input)\n",
    "        \n",
    "        output_raw_emb, self.hidden = self.rnn(input, self.hidden)\n",
    "        if pack:\n",
    "            output_raw_emb, output_len = pad_packed_sequence(output_raw_emb, batch_first=True)\n",
    "        \n",
    "        if self.has_output:\n",
    "            output_raw = self.output(output_raw_emb)\n",
    "            \n",
    "        if pack:\n",
    "            output_raw_packed = pack_padded_sequence(output_raw, lengths=output_len, batch_first=True)\n",
    "            return output_raw_emb, output_raw, output_len\n",
    "        \n",
    "        # return hidden state at each time step\n",
    "        return output_raw_emb, output_raw, output_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphRNN(input_size=max_prev_node, \n",
    "                 embedding_size=max_prev_node, \n",
    "                 output_size=edge_rnn_embedding_size, \n",
    "                 has_output=True, \n",
    "                 hidden_size=embedding_size, \n",
    "                 num_layers=4, \n",
    "                 has_input=False).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_nn = GraphRNN(input_size=1, \n",
    "                   embedding_size=edge_rnn_embedding_size,\n",
    "                   hidden_size=edge_rnn_embedding_size, \n",
    "                   num_layers=4, has_input=True, has_output=True, \n",
    "                   output_size=1).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FeaturesGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "import torch_cluster\n",
    "import torch_geometric\n",
    "\n",
    "from torch_geometric.nn import NNConv, GCNConv, GraphConv\n",
    "from torch_geometric.nn import PointConv, EdgeConv, SplineConv\n",
    "\n",
    "\n",
    "class FeaturesGCN(torch.nn.Module):\n",
    "    def __init__(self, dim_in, embedding_size=128, num_layers=4, dim_out=6):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.wconv_in = EdgeConv(Sequential(nn.Linear(dim_in * 2, embedding_size)), 'max')\n",
    "        \n",
    "        self.layers = nn.ModuleList(modules=[EdgeConv(Sequential(nn.Linear(embedding_size * 2, embedding_size)), 'max')\n",
    "                                   for i in range(num_layers)])\n",
    "\n",
    "        self.wconv_out = EdgeConv(Sequential(nn.Linear(embedding_size * 2, dim_out)), 'max')\n",
    "\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.wconv_in(x=x, edge_index=edge_index)\n",
    "        \n",
    "        for l in self.layers:\n",
    "            x = l(x=x, edge_index=edge_index)\n",
    "        \n",
    "        x = self.wconv_out(x=x, edge_index=edge_index)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_nn = FeaturesGCN(dim_in=edge_rnn_embedding_size * max_prev_node, \n",
    "                          embedding_size=128, num_layers=4,\n",
    "                          dim_out=5).to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = nn.Sigmoid().to(device)\n",
    "loss_bce = nn.BCELoss().to(device)\n",
    "loss_mse = torch.nn.MSELoss().to(device)\n",
    "\n",
    "def loss_mse_edges(shower, features):\n",
    "    return loss_mse((shower.x[0][shower.adj_out[0]] - shower.x[0][shower.adj_out[1]]), \n",
    "                    (features[shower.adj_out[0]] - features[shower.adj_out[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process_train_graphrnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import PackedSequence\n",
    "\n",
    "def process_train_graphrnn(showers_batch):\n",
    "    batch_size = len(showers_batch)\n",
    "    \n",
    "    model.hidden = model.init_hidden(input=torch.stack([x.ele_p for x in showers_batch]).view(-1, 1), \n",
    "                                     batch_size=batch_size)\n",
    "    \n",
    "    packed_adj_batch = pack_sequence([x.adj[0] for x in showers_batch])\n",
    "    _, embedding_batch, output_len = model(packed_adj_batch, pack=True)\n",
    "\n",
    "    packed_embedding_batch = pack_padded_sequence(embedding_batch, output_len, batch_first=True).data\n",
    "    \n",
    "    hidden_null = torch.zeros(4 - 1, packed_embedding_batch.shape[0], packed_embedding_batch.shape[1]).to(device)\n",
    "    edge_nn.hidden = torch.cat((packed_embedding_batch.view(1, \n",
    "                                                            packed_embedding_batch.size(0), \n",
    "                                                            packed_embedding_batch.size(1)), hidden_null), dim=0)\n",
    "    packed_adj_batch_data = packed_adj_batch.data\n",
    "    packed_adj_batch_data = packed_adj_batch_data.view(packed_adj_batch_data.shape[0], \n",
    "                                                       packed_adj_batch_data.shape[1], 1)\n",
    "    \n",
    "    packed_adj_batch = torch.cat((torch.ones(packed_adj_batch_data.shape[0], 1, 1).to(device), \n",
    "                                  packed_adj_batch_data[:, 0:-1, 0:1]), dim=1)\n",
    "    \n",
    "    edges_emb, edges, _ = edge_nn(packed_adj_batch)\n",
    "    return embedding_batch, output_len, pad_packed_sequence(PackedSequence(edges_emb.contiguous().view(edges_emb.size(0), -1), output_len))[0], loss_bce(torch.sigmoid(edges), packed_adj_batch_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showers_batch = showers_train\n",
    "showers_batch = sorted(showers_batch, key=lambda x: -x.adj.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_batch, output_len, edges, ll_bce = process_train_graphrnn(showers_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization of edge predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "learning_rate = 1e-5\n",
    "optimizer_bce = torch.optim.Adam(list(model.parameters()) + \n",
    "                                 list(edge_nn.parameters()), \n",
    "                                 lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "edge_nn.train()\n",
    "\n",
    "for i in tqdm(range(5000)):\n",
    "    optimizer_bce.zero_grad()\n",
    "    \n",
    "    showers_batch = showers_train # random.sample(showers_train, batch_size)\n",
    "    showers_batch = sorted(showers_batch, key=lambda x: -x.adj.shape[1])\n",
    "    \n",
    "    # iterate over showers in batch\n",
    "    # and calc losses\n",
    "    embedding_batch, output_len, edges_emb, ll_bce = process_train_graphrnn(showers_batch)\n",
    "\n",
    "    ll_bce.backward()\n",
    "    \n",
    "    optimizer_bce.step()\n",
    "    \n",
    "    print(ll_bce.item())\n",
    "    \n",
    "    del embedding_batch, output_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization of feature reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "optimizer_mse = torch.optim.Adam(list(features_nn.parameters()), \n",
    "                                 lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(3000)):\n",
    "    optimizer_mse.zero_grad()\n",
    "    \n",
    "    showers_batch = showers_train # random.sample(showers_train, batch_size)\n",
    "    showers_batch = sorted(showers_batch, key=lambda x: -x.adj.shape[1])\n",
    "    \n",
    "    # iterate over showers in batch\n",
    "    # and calc losses\n",
    "    _, output_len, edges_emb, ll_bce = process_train_graphrnn(showers_batch)\n",
    "    \n",
    "    ll_mse_edges = []\n",
    "    \n",
    "    # iterate over showers in batch\n",
    "    # and calc losses\n",
    "    for k, l in enumerate(output_len):\n",
    "        shower = showers_batch[k]\n",
    "        \n",
    "        embedding = edges_emb[k][:l]\n",
    "\n",
    "        # teacher forcing\n",
    "        shower_t = torch_geometric.data.Data(x=embedding, \n",
    "                                             edge_index=shower.adj_out).to(device)\n",
    "        \n",
    "        # GCN to recover shower features\n",
    "        features = features_nn(shower_t)\n",
    "    \n",
    "        # features prediction loss        \n",
    "        ll_mse_edges.append(loss_mse_edges(shower, features))\n",
    "        \n",
    "        del shower_t, features\n",
    "\n",
    "    ll_mse_edges = sum(ll_mse_edges) / len(ll_mse_edges)\n",
    "    \n",
    "    ll_mse_edges.backward()\n",
    "    \n",
    "    optimizer_mse.step()\n",
    "    \n",
    "    del edges_emb, output_len\n",
    "    \n",
    "    print(ll_bce.item(), \n",
    "          ll_mse_edges.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.3e-5\n",
    "optimizer_fine = torch.optim.Adam(list(features_nn.parameters()) +\n",
    "                                  list(edge_nn.parameters()) +\n",
    "                                  list(model.parameters()), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_vector = torch.tensor([1e1, 1e1, 1e1, 1, 1]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_mse_edges(shower, features, scale_vector):\n",
    "    return loss_mse((shower.x[0][shower.adj_out[0]] - shower.x[0][shower.adj_out[1]]) * scale_vector, \n",
    "                    (features[shower.adj_out[0]] - features[shower.adj_out[1]]) * scale_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(5000)):\n",
    "    optimizer_fine.zero_grad()\n",
    "    \n",
    "    showers_batch = showers_train # random.sample(showers_train, batch_size)\n",
    "    showers_batch = sorted(showers_batch, key=lambda x: -x.adj.shape[1])\n",
    "    \n",
    "    # iterate over showers in batch\n",
    "    # and calc losses\n",
    "    _, output_len, edges_emb, ll_bce = process_train_graphrnn(showers_batch)\n",
    "    \n",
    "    ll_mse_edges = []\n",
    "    \n",
    "    # iterate over showers in batch\n",
    "    # and calc losses\n",
    "    for k, l in enumerate(output_len):\n",
    "        shower = showers_batch[k]\n",
    "        \n",
    "        embedding = edges_emb[k][:l]\n",
    "\n",
    "        # teacher forcing\n",
    "        shower_t = torch_geometric.data.Data(x=embedding, \n",
    "                                             edge_index=shower.adj_out).to(device)\n",
    "        \n",
    "        # GCN to recover shower features\n",
    "        features = features_nn(shower_t)\n",
    "    \n",
    "        # features prediction loss        \n",
    "        ll_mse_edges.append(loss_mse_edges(shower, features, scale_vector))\n",
    "        \n",
    "        del shower_t, features\n",
    "\n",
    "    ll_mse_edges = sum(ll_mse_edges) / len(ll_mse_edges)\n",
    "    \n",
    "    (ll_bce + ll_mse_edges * 20).backward()\n",
    "    \n",
    "    optimizer_fine.step()\n",
    "    \n",
    "    print(ll_bce.item(), \n",
    "          ll_mse_edges.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.opera_tools import plot_npframe\n",
    "plot_npframe(shower.x.cpu().detach().numpy()[0] * np.array([1e4, 1e4, 1e4, 1, 1]))\n",
    "\n",
    "tmp_X = features.cpu().detach().numpy()[:, :5]\n",
    "tmp_X *= np.array([1e4, 1e4, 1e4, 1, 1])\n",
    "plot_npframe(tmp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teacher forcing\n",
    "shower_t = torch_geometric.data.Data(x=embedding, \n",
    "                                     edge_index=shower.adj_out).to(device)\n",
    "\n",
    "# GCN to recover shower features\n",
    "features = features_nn(shower_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shower.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(shower.x[0][shower.adj_out[0]] - shower.x[0][shower.adj_out[1]]) - (features[shower.adj_out[0]] - features[shower.adj_out[1]]) * torch.tensor([1e4, 1e4, 1e4, 1, 1]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.opera_tools import plot_npframe\n",
    "plot_npframe(shower.x.cpu().detach().numpy()[0] * np.array([1e4, 1e4, 1e4, 1, 1]))\n",
    "\n",
    "tmp_X = features.cpu().detach().numpy()[:, :5]\n",
    "tmp_X *= np.array([1e4, 1e4, 1e4, 1, 1])\n",
    "plot_npframe(tmp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph(adj):\n",
    "    '''\n",
    "    get a graph from zero-padded adj\n",
    "    :param adj:\n",
    "    :return:\n",
    "    '''\n",
    "    # remove all zeros rows and columns\n",
    "    adj = adj[~np.all(adj == 0, axis=1)]\n",
    "    adj = adj[:, ~np.all(adj == 0, axis=0)]\n",
    "    adj = np.asmatrix(adj)\n",
    "    G = nx.from_numpy_matrix(adj)\n",
    "    return G\n",
    "\n",
    "def generate_graph(model, edge_nn, max_prev_node, test_batch_energies, device):\n",
    "    test_batch_size = test_batch_energies.shape[0]\n",
    "    model.hidden = model.init_hidden(test_batch_energies, test_batch_size)\n",
    "    model.eval()\n",
    "    model.eval()\n",
    "\n",
    "    # generate graphs\n",
    "    max_num_node = 200\n",
    "    \n",
    "    y_pred_long = torch.ones(test_batch_size, \n",
    "                             max_num_node, \n",
    "                             max_prev_node).to(device) # discrete prediction\n",
    "    \n",
    "    x_step = torch.zeros(test_batch_size, 1, max_prev_node).to(device)\n",
    "    for i in tqdm(range(max_num_node)):\n",
    "        _, h, _ = model(x_step)\n",
    "        hidden_null = torch.zeros(edge_nn.num_layers - 1, h.size(0), h.size(2)).cuda()\n",
    "        edge_nn.hidden = torch.cat((h.permute(1, 0, 2), hidden_null), dim=0)  # num_layers, batch_size, hidden_size\n",
    "        x_step = torch.zeros(test_batch_size, 1, max_prev_node).to(device)\n",
    "        output_x_step = torch.ones(test_batch_size, 1, 1).to(device)\n",
    "        for j in range(min(max_prev_node, i+1)):\n",
    "            _, output_y_pred_step, _ = edge_nn(output_x_step)\n",
    "            output_x_step = Bernoulli(logits=output_y_pred_step).sample()\n",
    "            x_step[:, :, j:j+1] = output_x_step\n",
    "            # edge_nn.hidden = hidden.data\n",
    "        y_pred_long[:, i:i + 1, :] = x_step\n",
    "        model.hidden = model.hidden.data\n",
    "    print(y_pred_long)\n",
    "    y_pred_long_data = y_pred_long.data.long()\n",
    "    \n",
    "    # save graphs as pickle\n",
    "    G_pred_list = []\n",
    "    for i in range(test_batch_size):\n",
    "        adj_pred = decode_adj(y_pred_long_data[i].detach().cpu().numpy())\n",
    "        G_pred = get_graph(adj_pred) # get a graph from zero-padded adj\n",
    "        G_pred_list.append(G_pred)\n",
    "        \n",
    "        # teacher forcing\n",
    "        shower_t = torch_geometric.data.Data(x=embedding, \n",
    "                                             edge_index=shower.adj_out).to(device)\n",
    "        \n",
    "        # GCN to recover shower features\n",
    "        features = features_nn(shower_t)\n",
    "\n",
    "    return G_pred_list\n",
    "\n",
    "\n",
    "a = generate_graph(model=model, \n",
    "                   edge_nn=edge_nn,\n",
    "                   max_prev_node=max_prev_node, \n",
    "                   test_batch_energies=torch.tensor([6.6297] * 10).to(device).view(-1, 1), \n",
    "                   device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.DiGraph(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_out_t = torch.LongTensor(np.array(list(g.edges())).T).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shower_t = torch_geometric.data.Data(x=embedding, \n",
    "                                     edge_index=shower.adj_out).to(device)\n",
    "\n",
    "features = features_nn(shower_t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
